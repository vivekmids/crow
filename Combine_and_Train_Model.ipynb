{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# define combined model\n",
    "# !!! keep the top layers consistent with the custom model\n",
    "x = model_transfer.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(10, activation=\"softmax\")(x)\n",
    "model_combined = Model(model_transfer.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom layer weights\n",
    "model.load_weights('model_4.h5')  # update this with the most up-to-date weights, 'model' is the custom model\n",
    "\n",
    "# get weights for inception v3 and for custom layers\n",
    "inceptionv3_weights = model_transfer.get_weights()\n",
    "top_layer_weights = model.get_weights()\n",
    "\n",
    "# combine weights\n",
    "combined_weights = inceptionv3_weights + top_layer_weights\n",
    "\n",
    "# set weights for combined model\n",
    "model_combined.set_weights(combined_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "4\n",
      "380\n"
     ]
    }
   ],
   "source": [
    "print(len(inceptionv3_weights))\n",
    "print(len(top_layer_weights))\n",
    "print(len(combined_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue training combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize(size=(299,299))\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0\n",
    "    # Convert 2-dim gray-scale array to 3-dim RGB array.\n",
    "    # if (len(img.shape) == 2):\n",
    "    #     img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X_data, y_data, batch_size):\n",
    "    i = 0\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            if i >= len(X_data):\n",
    "                i = 0\n",
    "                \n",
    "            X = X_data[i]\n",
    "            y = y_data[i]\n",
    "            X = load_image(X)\n",
    "            X_batch.append(X)\n",
    "            y_batch.append(y)\n",
    "            i += 1\n",
    "            \n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_dist = dict(image_df_annot.groupby('category_id_model').image_id.count().sort_values())\n",
    "total = sum(class_dist.values())\n",
    "class_dist_inverse = {k: total/v for k, v in class_dist.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6: 128.48837209302326,\n",
       " 0: 56.905430711610485,\n",
       " 1: 54.851083032490976,\n",
       " 3: 25.533032244512132,\n",
       " 5: 22.13823877606775,\n",
       " 4: 19.940940037732755,\n",
       " 2: 19.692183070068854,\n",
       " 7: 14.614644703619094,\n",
       " 8: 5.391798079268969,\n",
       " 9: 1.9332776651159091}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dist_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 1024 images\n",
    "sample_x_train = img_vector_train[:1024]\n",
    "sample_y_train = cat_id_vector_train[:1024]\n",
    "sample_x_val = img_vector_val[:64]\n",
    "sample_y_val = cat_id_vector_val[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-69-0e4d9ccb5db9>:28: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate for 16 steps\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      " 3/16 [====>.........................] - ETA: 5:10 - loss: 27.1582 - accuracy: 0.3385"
     ]
    }
   ],
   "source": [
    "# without reducing empty class, 10 class with adjusted class weights\n",
    "# train full model incl. inception v3 layers\n",
    "\n",
    "X_train = sample_x_train\n",
    "y_train = sample_y_train\n",
    "X_val = sample_x_val\n",
    "y_val = sample_y_val\n",
    "\n",
    "# X_train = img_vector_train\n",
    "# y_train = cat_id_vector_train\n",
    "# X_val = img_vector_val\n",
    "# y_val = cat_id_vector_val\n",
    "\n",
    "EPOCH = 2\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_STEPS = len(X_train)//BATCH_SIZE\n",
    "VAL_STEPS = len(y_train)//BATCH_SIZE\n",
    "\n",
    "train_generator = generator(X_train, y_train, BATCH_SIZE)\n",
    "val_generator = generator(X_val, y_val, BATCH_SIZE)\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    model_combined.fit_generator(generator=train_generator, \\\n",
    "                        validation_data=val_generator,\\\n",
    "                        validation_steps=VAL_STEPS, \\\n",
    "                        steps_per_epoch=TRAIN_STEPS, \\\n",
    "                        epochs=1, verbose=1,\\\n",
    "                        class_weight=class_dist_inverse)\n",
    "                        #use_multiprocessing=True)\n",
    "    model_combined.save('./weights/combined/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
