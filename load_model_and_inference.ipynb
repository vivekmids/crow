{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['skunk','fox','rodent','dog','squirrel','cat','rabbit','bird','cow','bobcat','deer','raccoon','coyote','opossum','other']\n",
    "classes_dict_lookup = dict(zip(range(15), classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('edge/model/combined_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize(size=(299,299), resample=Image.LANCZOS).convert(\"RGB\")\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0\n",
    "    # Convert 2-dim gray-scale array to 3-dim RGB array.\n",
    "    if (len(img.shape) == 2):\n",
    "        img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted_id = model.predict(load_image('data/cct_images/59439fd8-23d2-11e8-a6a3-ec086b02610b.jpg').reshape(1, 299, 299, 3))\n",
    "predicted_id = model.predict(load_image('Siberian_roe_deer.jpg').reshape(1, 299, 299, 3))\n",
    "predicted_name = classes_dict_lookup[predicted_id.argmax()]\n",
    "predicted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1608334e-16, 6.1869932e-13, 1.1558397e-17, 2.6659878e-08,\n",
       "        1.8537663e-11, 2.9166957e-11, 2.6647168e-08, 5.7530478e-09,\n",
       "        5.5706734e-10, 3.9642853e-09, 9.9999940e-01, 2.7073899e-10,\n",
       "        2.7802943e-07, 1.0279425e-10, 3.4708441e-07]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = load_image('Siberian_roe_deer.jpg').reshape(1, 299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(img_array)\n",
    "im.save(\"your_file.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Lite and Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: edge/model/assets\n"
     ]
    }
   ],
   "source": [
    "#tf.saved_model.save(model,'edge/model/')\n",
    "#converter = tf.lite.TFLiteConverter.from_saved_model('edge/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89227712"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open(\"edge/model/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22393728"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"edge/model/converted_quant_model.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference on TF Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"edge/model/converted_quant_model.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'input_17',\n",
       " 'index': 1,\n",
       " 'shape': array([  1, 299, 299,   3], dtype=int32),\n",
       " 'dtype': numpy.float32,\n",
       " 'quantization': (0.0, 0)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = img_array.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on random input data.\n",
    "#input_shape = input_details[0]['shape']\n",
    "#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7996434e-16 1.5633627e-13 4.1054564e-19 6.2364132e-09 4.8039034e-12\n",
      "  1.0180091e-11 7.3228819e-09 1.2886735e-09 2.8510355e-10 2.7699304e-10\n",
      "  9.9999976e-01 5.6435346e-11 6.2987461e-08 2.2626739e-11 6.7611658e-08]]\n"
     ]
    }
   ],
   "source": [
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict_lookup[predictions.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Here lies logic to load the model\"\"\"\n",
    "    # load model from h5 file\n",
    "    \n",
    "    model = tf.lite.Interpreter(model_path=\"edge/model/converted_quant_model.tflite\")\n",
    "    model.allocate_tensors()\n",
    "#    input_details = model.get_input_details()\n",
    "#    output_details = model.get_output_details()\n",
    "    \n",
    "    # Test model on random input data.\n",
    "#    input_shape = input_details[0]['shape']\n",
    "#    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "#    model.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "#    model.invoke()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, image):\n",
    "    \"\"\"Here is the code that to perform inference using the model.\n",
    "    Expect this to be the model you return in `load_model()`\n",
    "\n",
    "    Args:\n",
    "        model: one built using load_model\n",
    "        image: numpy array as created by opencv\n",
    "\n",
    "    Returns: bool, list(string)\n",
    "        - a boolean to signal we found something\n",
    "        - name of identified animals\n",
    "    \"\"\"\n",
    "    \n",
    "    classes = ['skunk','fox','rodent','dog','squirrel','cat','rabbit','bird','cow','bobcat','deer','raccoon','coyote','opossum']\n",
    "    classes_dict_lookup = dict(zip(range(15), classes+['other']))\n",
    "    \n",
    "    # run inference\n",
    "    model.set_tensor(1, image)\n",
    "    model.invoke()\n",
    "    \n",
    "    predicted_id = model.get_tensor(0)\n",
    "    predicted_name = classes_dict_lookup[predicted_id.argmax()]\n",
    "    \n",
    "    if predicted_name in classes:\n",
    "        return True, predicted_name\n",
    "    else:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = load_image('Siberian_roe_deer.jpg').reshape(1, 299, 299, 3)\n",
    "input_data = img_array.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_something, detected_animals = infer(model, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "deer\n"
     ]
    }
   ],
   "source": [
    "print(found_something)\n",
    "print(detected_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
